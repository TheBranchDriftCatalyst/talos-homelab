---
# LobeChat - Modern ChatGPT-like UI with Ollama support
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lobe-chat
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: lobe-chat
    app.kubernetes.io/component: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: lobe-chat
  template:
    metadata:
      labels:
        app: lobe-chat
        app.kubernetes.io/name: lobe-chat
    spec:
      containers:
        - name: lobe-chat
          image: lobehub/lobe-chat:latest
          ports:
            - containerPort: 3210
              name: http
          env:
            # Ollama configuration - point to llm-proxy for scale-to-zero
            - name: OLLAMA_PROXY_URL
              value: 'http://llm-proxy:8080'
            # Enable Ollama provider
            - name: ENABLED_OLLAMA
              value: 'true'
            # Disable other providers (homelab, Ollama only)
            - name: ENABLED_OPENAI
              value: 'false'
            - name: ENABLED_ANTHROPIC
              value: 'false'
            - name: ENABLED_GOOGLE
              value: 'false'
            # Allow any origin (homelab)
            - name: ACCESS_CONTROL_ALLOW_ORIGIN
              value: '*'
            # App URL for SSR
            - name: APP_URL
              value: 'http://lobe.talos00'
          resources:
            requests:
              cpu: 100m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /
              port: 3210
            initialDelaySeconds: 30
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /
              port: 3210
            initialDelaySeconds: 10
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: lobe-chat
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: lobe-chat
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 3210
      targetPort: 3210
  selector:
    app: lobe-chat
