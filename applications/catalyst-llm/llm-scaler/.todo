# LLM Scaler/Proxy - Task Index
# Tracked in beads (bd list --labels=catalyst-llm)

## Architecture
- [ ] TALOS-x3ik: Implement RabbitMQ broker for LLM routing (P2)
      Replace HTTP proxy with message broker for decoupled scaling
      - Request/reply queues per model
      - Priority queues (interactive vs batch)
      - Worker registration via heartbeats
      - Dead-letter handling for failed requests

## Active Work
- [ ] TALOS-klyu: Add EC2 instance failsafes (P2)
      Control-plane + self-destruct watchdog for cost control

- [ ] TALOS-pzv6: Add priority and autostart to Ollama providers (P2)
      Priority-based backend selection + on-demand provider activation

- [ ] TALOS-ouc2: Add header-based routing (P2)
      `x-cllm-proxy-agent-name` / `x-cllm-proxy-model-name` headers

## UI Features
- [ ] TALOS-38f3: Display model storage PV sizes on worker cards (P3)
      Show disk usage for model volumes, warn when near capacity

- [ ] TALOS-4dj1: Redesign dashboard with worker cards (P3)
      Blocked by: TALOS-xv6z
      - Worker cards with status, metrics, kill switches
      - Top bar with worker selector dropdown
      - Resizable logs drawer
      - URL-based tab routing

## Refactoring
- [ ] TALOS-i53f: Rename llm-scaler to llm-proxy (P3)
      Better reflects its role as a routing proxy

- [ ] TALOS-xv6z: Migrate UI to catalyst-ui + Vite (P3)
      Port embedded UI to React/TypeScript with catalyst-ui components

## Completed
- [x] TALOS-q501: Fix Nebula mesh for EC2 GPU worker
- [x] TALOS-ahlu: Add uncensored models to Ollama + ConfigMap

---
Run `bd show TALOS-xxxx` for full issue details
<!-- Edit this file and ask Claude to ingest new items into beads -->
