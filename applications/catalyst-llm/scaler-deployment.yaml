---
# LLM Scaler - Scale-to-zero proxy for AWS Ollama worker
# Automatically starts/stops EC2 instance based on request activity
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-scaler
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: llm-scaler
    app.kubernetes.io/component: proxy
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: llm-scaler
  template:
    metadata:
      labels:
        app.kubernetes.io/name: llm-scaler
        app.kubernetes.io/component: proxy
    spec:
      serviceAccountName: llm-scaler
      containers:
        - name: scaler
          image: ghcr.io/thebranchdriftcatalyst/llm-scaler:latest
          ports:
            - name: http
              containerPort: 8080
            - name: metrics
              containerPort: 9090
          env:
            - name: LISTEN_ADDR
              value: ':8080'
            - name: METRICS_ADDR
              value: ':9090'
            # Primary: Local ollama on talos06 (fallback/always-on)
            - name: OLLAMA_URL
              value: 'http://ollama-local.catalyst-llm.svc.cluster.local:11434'
            # Reduced idle timeout to 15 mins to save costs
            - name: IDLE_TIMEOUT
              value: '15m'
            # Remote AWS instance (for bigger models when needed)
            - name: REMOTE_OLLAMA_URL
              value: 'http://10.42.2.1:11434'
            - name: WARMUP_TIMEOUT
              value: '5m'
            - name: WORKER_SCRIPT
              value: '/app/llm-worker.sh'
            - name: AWS_REGION
              value: 'us-west-2'
            - name: STATE_FILE
              value: '/app/.output/worker-state.json'
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
          volumeMounts:
            - name: worker-state
              mountPath: /app/.output
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 2
            periodSeconds: 10
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
      volumes:
        - name: worker-state
          persistentVolumeClaim:
            claimName: llm-scaler-state
---
apiVersion: v1
kind: Service
metadata:
  name: llm-scaler
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: llm-scaler
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8080
      targetPort: http
    - name: metrics
      port: 9090
      targetPort: metrics
  selector:
    app.kubernetes.io/name: llm-scaler
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: llm-scaler
  namespace: catalyst-llm
---
# ServiceMonitor for Prometheus scraping
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: llm-scaler
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: llm-scaler
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: llm-scaler
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
