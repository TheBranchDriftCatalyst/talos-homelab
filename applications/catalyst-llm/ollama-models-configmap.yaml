---
# Ollama Model Configuration
# Edit this ConfigMap to manage which models are pulled to local Ollama
# After editing, restart the ollama deployment to trigger the init container
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-models
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: ollama
    app.kubernetes.io/part-of: catalyst-llm
data:
  # List of models to pull on startup (one per line)
  # Format: model_name:tag
  # Use # for comments
  models.txt: |
    # === Base Models ===
    llama3.2:latest
    mistral:latest
    qwen2.5-coder:7b

    # === Uncensored Models ===
    # Dolphin series - Eric Hartford's fine-tuned uncensored models
    dolphin-llama3:8b
    dolphin-mistral

    # Llama 2 Uncensored - based on Meta's Llama 2
    llama2-uncensored

    # Wizard Vicuna - 13B uncensored
    wizard-vicuna-uncensored:13b

    # Nous Hermes - lower hallucination rate
    nous-hermes2

    # === Abliterated Models (newer technique) ===
    # These have refusal behavior surgically removed
    huihui_ai/mistral-small-abliterated
