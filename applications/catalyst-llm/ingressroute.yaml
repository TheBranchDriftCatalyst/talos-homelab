---
# ServersTransport with extended timeout for LLM requests
# LLM inference can take 30+ seconds
apiVersion: traefik.io/v1alpha1
kind: ServersTransport
metadata:
  name: llm-transport
  namespace: catalyst-llm
spec:
  forwardingTimeouts:
    dialTimeout: 60s
    responseHeaderTimeout: 120s
    idleConnTimeout: 120s
---
# IngressRoute for Catalyst LLM API via scaler (scale-to-zero)
# Routes through llm-scaler which manages EC2 worker lifecycle
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: catalyst-llm-api
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: catalyst-llm
    app.kubernetes.io/component: ingress
  annotations:
    description: 'Scale-to-zero LLM proxy - auto starts/stops EC2 worker'
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`llm.talos00`)
      kind: Rule
      services:
        - name: llm-scaler
          port: 8080
          serversTransport: llm-transport
---
# IngressRoute for Ollama via scaler (scale-to-zero)
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: ollama
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: catalyst-llm
    app.kubernetes.io/component: ingress
  annotations:
    description: 'Scale-to-zero Ollama - auto starts/stops EC2 worker'
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`ollama.talos00`)
      kind: Rule
      services:
        - name: llm-scaler
          port: 8080
          serversTransport: llm-transport
---
# IngressRoute for direct Ollama access (bypasses scaler, worker must be running)
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: ollama-direct
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: catalyst-llm
    app.kubernetes.io/component: ingress
  annotations:
    description: 'Direct Ollama access - bypasses scaler, worker must be running'
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`ollama-direct.talos00`)
      kind: Rule
      services:
        - name: ollama-remote
          port: 11434
          serversTransport: llm-transport
---
# IngressRoute for Open-WebUI
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: open-webui
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: open-webui
    app.kubernetes.io/component: ingress
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`chat.talos00`)
      kind: Rule
      services:
        - name: open-webui
          port: 8080
          serversTransport: llm-transport
---
# IngressRoute for SillyTavern
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: sillytavern
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: sillytavern
    app.kubernetes.io/component: ingress
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`sillytavern.talos00`)
      kind: Rule
      services:
        - name: sillytavern
          port: 8000
---
# IngressRoute for SearXNG
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: searxng
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: searxng
    app.kubernetes.io/component: ingress
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`searxng.talos00`)
      kind: Rule
      services:
        - name: searxng
          port: 8080
---
# IngressRoute for LobeChat
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: lobe-chat
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: lobe-chat
    app.kubernetes.io/component: ingress
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`lobe.talos00`)
      kind: Rule
      services:
        - name: lobe-chat
          port: 3210
          serversTransport: llm-transport
---
# IngressRoute for LLM Scaler Dashboard
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: llm-scaler-dashboard
  namespace: catalyst-llm
  labels:
    app.kubernetes.io/name: llm-scaler
    app.kubernetes.io/component: ingress
  annotations:
    description: 'LLM Scaler dashboard - pause/resume and status'
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`llm-scaler.talos00`)
      kind: Rule
      services:
        - name: llm-scaler
          port: 8080
