# GitOps Homelab Progress Summary

**Last Updated**: 2025-11-10

## âœ… Completed Work

### Phase 1: Infrastructure Foundation (100% Complete)

#### 1. Directory Structure âœ…
Created complete GitOps directory structure:
```
talos-fix/
â”œâ”€â”€ bootstrap/          # GitOps bootstrap configs
â”‚   â”œâ”€â”€ flux/          # FluxCD installation
â”‚   â””â”€â”€ argocd/        # ArgoCD installation
â”œâ”€â”€ infrastructure/     # Infrastructure components
â”‚   â”œâ”€â”€ base/          # Base configurations
â”‚   â”‚   â”œâ”€â”€ namespaces/
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ traefik/
â”‚   â”‚   â””â”€â”€ monitoring/
â”‚   â””â”€â”€ overlays/      # Environment-specific
â”‚       â”œâ”€â”€ dev/
â”‚       â””â”€â”€ prod/
â”œâ”€â”€ applications/       # Application deployments
â”‚   â””â”€â”€ arr-stack/
â”‚       â”œâ”€â”€ base/
â”‚       â”‚   â”œâ”€â”€ prowlarr/
â”‚       â”‚   â”œâ”€â”€ sonarr/
â”‚       â”‚   â”œâ”€â”€ radarr/
â”‚       â”‚   â”œâ”€â”€ plex/
â”‚       â”‚   â””â”€â”€ jellyfin/
â”‚       â””â”€â”€ overlays/
â”‚           â”œâ”€â”€ dev/
â”‚           â””â”€â”€ prod/
â”œâ”€â”€ clusters/           # Cluster-specific configs
â”‚   â””â”€â”€ homelab-single/
â”œâ”€â”€ argocd-apps/        # ArgoCD Application definitions
â””â”€â”€ docs/               # Documentation
```

#### 2. Namespace Manifests âœ…
- **media-dev** namespace with:
  - ResourceQuota: 4 CPU / 8Gi RAM
  - LimitRange: Container limits and defaults
  - Pod security: baseline enforcement

- **media-prod** namespace with:
  - ResourceQuota: 8 CPU / 16Gi RAM
  - LimitRange: Higher container limits
  - Pod security: baseline enforcement

#### 3. Storage Configuration âœ…

**NFS Storage (Synology):**
- StorageClass: `nfs-synology`
- PersistentVolume: `nfs-media` (1Ti, ReadWriteMany)
- PersistentVolume: `nfs-downloads` (200Gi, ReadWriteMany)
- PVCs created for both dev and prod namespaces
- Mount options optimized: hard, nfsvers=4.1, noatime

**Local Path Provisioner:**
- Complete deployment manifest
- StorageClass: `local-path` (default)
- For SQLite databases (critical for arr apps)
- Volume path: `/var/lib/rancher/local-path-provisioner`

#### 4. Monitoring Stack âœ…

**kube-prometheus-stack HelmRelease:**
- Prometheus with 30d retention, 50Gi storage
- Alertmanager with 10Gi storage
- Grafana with persistence enabled
- Node Exporter enabled
- Kube State Metrics enabled
- ServiceMonitors configured
- IngressRoutes for Grafana, Prometheus, Alertmanager
- Resource limits configured for single-node homelab

#### 5. FluxCD Bootstrap âœ…

**Flux Manifests:**
- Namespace configuration
- Kustomization for namespaces (first priority)
- Kustomization for storage (second priority)
- Kustomization for monitoring
- Kustomization for infrastructure
- README with bootstrap instructions

**Cluster Configuration:**
- `clusters/homelab-single/` structure ready
- Flux sync configuration prepared
- Dependency ordering configured

#### 6. ArgoCD Bootstrap âœ…

**ArgoCD HelmRelease:**
- Deployed via FluxCD
- Admin password: "admin" (change after install!)
- Server configured with --insecure flag
- Redis, repo-server, controller configured
- ApplicationSet controller enabled
- IngressRoute: `http://argocd.lab`
- Resource limits configured
- README with access instructions

#### 7. Traefik Configuration âœ…

**Base Configuration:**
- HelmRelease for Traefik v3.5.x
- DaemonSet deployment with hostPort
- Dashboard IngressRoute with domain substitution
- Prometheus metrics enabled
- ServiceMonitor for kube-prometheus-stack

**Multi-Environment Support:**
- Dev overlay: `*.dev.lab` domains
- Prod overlay: `*.lab` domains
- ConfigMap-based domain substitution
- Kustomize patches for environment-specific routing

#### 8. Application Manifests âœ…

**Prowlarr (Indexer Manager):**
- Deployment with LinuxServer image
- Service (ClusterIP, port 9696)
- PVC (1Gi, local-path for SQLite)
- IngressRoute with domain substitution
- Health probes configured

**Sonarr (TV Automation):**
- Deployment with LinuxServer image
- Service (ClusterIP, port 8989)
- PVC (5Gi, local-path for SQLite)
- Volume mounts: config, media (NFS), downloads (NFS)
- IngressRoute with domain substitution
- Resource limits: 1 CPU / 1Gi RAM

**Radarr (Movie Automation):**
- Deployment with LinuxServer image
- Service (ClusterIP, port 7878)
- PVC (5Gi, local-path for SQLite)
- Volume mounts: config, media (NFS), downloads (NFS)
- IngressRoute with domain substitution
- Resource limits: 1 CPU / 1Gi RAM

**Plex Media Server:**
- Deployment with hostNetwork enabled
- Service (ClusterIP, port 32400)
- PVC (50Gi, local-path)
- Volume mounts: config, media (NFS read-only), transcode (emptyDir)
- IngressRoute with domain substitution
- Resource limits: 4 CPU / 4Gi RAM
- PLEX_CLAIM environment variable for setup

**Jellyfin Media Server:**
- Deployment with LinuxServer image
- Service (ClusterIP, ports 8096/8920)
- PVC (50Gi, local-path)
- Volume mounts: config, media (NFS read-only), transcode (emptyDir)
- IngressRoute with domain substitution
- Resource limits: 4 CPU / 4Gi RAM
- Health probes configured

### Phase 2: Local Testing Setup (100% Complete) âœ…

#### Local Cluster Provisioning âœ…

**provision-local.sh Script:**
- Creates Docker-based single-node Talos cluster
- Cluster name: `talos-local`
- Installs metrics-server with insecure TLS
- Installs Traefik with LoadBalancer service
- Deploys test whoami service
- Auto-merges kubeconfig to `~/.kube/config`
- Full error handling and colorized output

**Taskfile Commands:**
- `task provision-local` - Create local cluster
- `task destroy-local` - Destroy local cluster

**Documentation:**
- Complete LOCAL-TESTING.md guide
- Prerequisites and setup instructions
- Differences from production
- Troubleshooting section
- Port forwarding examples

## ğŸ“Š Current State

### Infrastructure
- âœ… Directory structure: Complete
- âœ… Namespaces: Complete (dev + prod)
- âœ… Storage: Complete (NFS + local-path)
- âœ… Monitoring: Complete (kube-prometheus-stack)
- âœ… GitOps: Complete (Flux + ArgoCD)
- âœ… Ingress: Complete (Traefik multi-env)

### Applications
- âœ… Prowlarr: Complete
- âœ… Sonarr: Complete
- âœ… Radarr: Complete
- âœ… Plex: Complete
- âœ… Jellyfin: Complete

### Testing
- âœ… Local cluster script: Complete
- âœ… Documentation: Complete
- â³ Local testing: Ready to execute

## ğŸ¯ Next Steps

### Immediate (Testing Phase)

1. **Test Local Cluster**
   ```bash
   task provision-local
   kubectl get nodes
   kubectl get pods -A
   ```

2. **Validate Kustomize Builds**
   ```bash
   kustomize build infrastructure/base
   kustomize build applications/arr-stack/base/prowlarr
   ```

3. **Deploy to Local Cluster**
   ```bash
   # Infrastructure
   kubectl apply -k infrastructure/base/namespaces/
   kubectl apply -k infrastructure/base/storage/

   # Test single app
   kubectl apply -k applications/arr-stack/base/prowlarr/
   kubectl -n media-dev get all
   kubectl -n media-dev port-forward svc/prowlarr 9696:9696
   ```

### Short Term (Production Deployment)

1. **Create Git Repository**
   - Initialize Git repo
   - Push all manifests
   - Tag initial release

2. **Bootstrap FluxCD**
   ```bash
   flux bootstrap github \
     --owner=<username> \
     --repository=<repo> \
     --branch=main \
     --path=clusters/homelab-single \
     --personal
   ```

3. **Verify Flux Reconciliation**
   ```bash
   flux get all
   flux get kustomizations
   kubectl -n flux-system logs -f deployment/source-controller
   ```

4. **Configure Synology NFS**
   - Create `/volume1/media` NFS share
   - Create `/volume1/downloads` NFS share
   - Configure NFS permissions (UID 1000, GID 1000)
   - Update `SYNOLOGY_NFS_SERVER` in overlay configs

5. **Create ArgoCD Applications**
   - Create Application manifests in `argocd-apps/`
   - Apply to cluster
   - Verify sync status

### Medium Term (Configuration)

1. **Configure Prowlarr**
   - Add indexers
   - Configure download clients
   - Test search functionality

2. **Configure Sonarr**
   - Connect to Prowlarr
   - Add root folder (/tv)
   - Configure quality profiles
   - Add series

3. **Configure Radarr**
   - Connect to Prowlarr
   - Add root folder (/movies)
   - Configure quality profiles
   - Add movies

4. **Configure Plex**
   - Claim server with PLEX_CLAIM token
   - Add media library (/data)
   - Configure transcoding
   - Test playback

5. **Configure Jellyfin**
   - Add media library (/data)
   - Configure transcoding
   - Compare with Plex performance

### Long Term (Enhancements)

1. **Add More Applications**
   - Overseerr/Jellyseerr (request management)
   - Bazarr (subtitle management)
   - Tautulli (Plex monitoring)
   - Organizr (dashboard)

2. **Enhance Monitoring**
   - Create custom Grafana dashboards
   - Configure Prometheus alerts
   - Set up alert routing

3. **Add Security**
   - Cert-manager for HTTPS
   - Let's Encrypt certificates
   - OAuth2 proxy for authentication

4. **Backup Strategy**
   - Velero for Kubernetes backup
   - Scheduled PVC snapshots
   - Configuration backup to Git

## ğŸ“ Configuration Notes

### Domain Configuration

**Development (`*.dev.lab`):**
- Grafana: `http://grafana.dev.lab`
- Prometheus: `http://prometheus.dev.lab`
- Alertmanager: `http://alertmanager.dev.lab`
- Prowlarr: `http://prowlarr.dev.lab`
- Sonarr: `http://sonarr.dev.lab`
- Radarr: `http://radarr.dev.lab`
- Plex: `http://plex.dev.lab`
- Jellyfin: `http://jellyfin.dev.lab`

**Production (`*.lab`):**
- Grafana: `http://grafana.lab`
- Prometheus: `http://prometheus.lab`
- Alertmanager: `http://alertmanager.lab`
- ArgoCD: `http://argocd.lab`
- Traefik: `http://traefik.lab`
- Prowlarr: `http://prowlarr.lab`
- Sonarr: `http://sonarr.lab`
- Radarr: `http://radarr.lab`
- Plex: `http://plex.lab`
- Jellyfin: `http://jellyfin.lab`

### Storage Requirements

**NFS (Synology):**
- Media Library: 1Ti (movies + TV shows)
- Downloads: 200Gi (temporary download location)
- Access Mode: ReadWriteMany (shared across pods)

**Local Path:**
- Prowlarr config: 1Gi (SQLite database)
- Sonarr config: 5Gi (SQLite database + metadata)
- Radarr config: 5Gi (SQLite database + metadata)
- Plex config: 50Gi (database + metadata + thumbnails)
- Jellyfin config: 50Gi (database + metadata + thumbnails)
- Prometheus: 50Gi (metrics retention)
- Grafana: 10Gi (dashboards + datasources)
- Alertmanager: 10Gi (alert history)

**Total Local Storage Required:** ~147Gi

### Resource Allocation

**Development Namespace:**
- Total Requests: 4 CPU / 8Gi RAM
- Total Limits: 8 CPU / 16Gi RAM
- Max per Container: 2 CPU / 4Gi RAM
- Max per Pod: 4 CPU / 8Gi RAM

**Production Namespace:**
- Total Requests: 8 CPU / 16Gi RAM
- Total Limits: 16 CPU / 32Gi RAM
- Max per Container: 4 CPU / 8Gi RAM
- Max per Pod: 8 CPU / 16Gi RAM

**Monitoring Namespace:**
- Prometheus: 500m-2 CPU / 2-4Gi RAM
- Grafana: 100m-500m CPU / 256Mi-512Mi RAM
- Alertmanager: 50m-200m CPU / 128Mi-256Mi RAM

## ğŸ”§ Tools Used

- **Talos Linux** v1.11.1 - Immutable Kubernetes OS
- **Kubernetes** v1.34.0 - Container orchestration
- **FluxCD** v2.x - Infrastructure GitOps
- **ArgoCD** v2.x - Application GitOps
- **Traefik** v3.5.3 - Ingress controller
- **kube-prometheus-stack** v65.x - Monitoring stack
- **Kustomize** - Configuration management
- **Helm** - Package management

## ğŸ“š Documentation Created

- âœ… IMPLEMENTATION-TRACKER.md - Project tracker
- âœ… PROGRESS-SUMMARY.md - This document
- âœ… LOCAL-TESTING.md - Local cluster guide
- âœ… bootstrap/flux/README.md - Flux setup
- âœ… bootstrap/argocd/README.md - ArgoCD setup

## ğŸ‰ Achievements

1. **Complete GitOps Infrastructure** - Dual GitOps with Flux (infra) + ArgoCD (apps)
2. **Multi-Environment Support** - Dev and Prod with Kustomize overlays
3. **Hybrid Storage Strategy** - NFS for media + local-path for databases
4. **Full Arr Stack** - Prowlarr, Sonarr, Radarr ready to deploy
5. **Dual Media Servers** - Plex and Jellyfin for comparison
6. **Comprehensive Monitoring** - Prometheus + Grafana + Alertmanager
7. **Local Testing Environment** - Docker-based Talos cluster for safe testing
8. **Production-Ready Manifests** - Resource limits, health probes, security contexts

Ready to test and deploy! ğŸš€
