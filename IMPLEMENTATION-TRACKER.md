# Homelab GitOps + Arr Stack Implementation Tracker

**Project Start**: 2025-11-09
**Target Completion**: 6 weeks
**Status**: ğŸš§ Phase 1 - Directory Structure Created

---

## Quick Status

| Phase                              | Status         | Progress |
| ---------------------------------- | -------------- | -------- |
| Phase 1: Directory Structure       | ğŸš§ IN PROGRESS | 25%      |
| Phase 2: GitOps Foundation         | â¸ï¸ PENDING     | 0%       |
| Phase 3: Multi-Environment         | â¸ï¸ PENDING     | 0%       |
| Phase 4: Storage Setup             | â¸ï¸ PENDING     | 0%       |
| Phase 5: Monitoring Stack          | â¸ï¸ PENDING     | 0%       |
| Phase 6: Arr Stack + Media Servers | â¸ï¸ PENDING     | 0%       |
| Phase 7: Finalize & Document       | â¸ï¸ PENDING     | 0%       |

**Overall Progress**: 4% (1/25 major tasks)

---

## Stack Overview

### Core Infrastructure

- **OS**: Talos Linux v1.11.1
- **Kubernetes**: v1.34.0
- **GitOps (Infra)**: FluxCD v2.x
- **GitOps (Apps)**: ArgoCD v2.x
- **Ingress**: Traefik v3.5.3
- **Monitoring**: kube-Prometheus-stack
- **Storage**: Synology NFS + local-path-provisioner

### Media Applications

- **Indexer Manager**: Prowlarr
- **TV Automation**: Sonarr
- **Movie Automation**: Radarr
- **Media Servers**: **Plex** (primary) + **Jellyfin** (testing/comparison)

### Environments

- **Dev**: `media-dev` namespace, `*.dev.lab` domains
- **Prod**: `media-prod` namespace, `*.lab` domains

---

## Phase 1: Directory Structure âœ… 25% Complete

### âœ… Completed Tasks

- [x] Created bootstrap directories (flux, ArgoCD)
- [x] Created infrastructure directories (base + overlays)
- [x] Created applications/arr-stack structure
- [x] Created base dirs for all apps (prowlarr, sonarr, radarr, plex, jellyfin)

### ğŸš§ In Progress

- [ ] Create namespace manifests
- [ ] Create storage provisioner manifests
- [ ] Create kube-Prometheus-stack configuration
- [ ] Create Flux bootstrap manifests
- [ ] Create ArgoCD bootstrap manifests

### Directory Structure

```
talos-fix/
â”œâ”€â”€ bootstrap/
â”‚   â”œâ”€â”€ flux/                    # FluxCD installation
â”‚   â””â”€â”€ argocd/                  # ArgoCD installation
â”œâ”€â”€ infrastructure/               # Managed by Flux
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ namespaces/          # media-dev, media-prod
â”‚   â”‚   â”œâ”€â”€ storage/             # NFS + local-path
â”‚   â”‚   â”œâ”€â”€ traefik/             # Ingress controller
â”‚   â”‚   â”œâ”€â”€ cert-manager/        # TLS certificates
â”‚   â”‚   â””â”€â”€ monitoring/
â”‚   â”‚       â””â”€â”€ kube-prometheus-stack/
â”‚   â””â”€â”€ overlays/
â”‚       â”œâ”€â”€ dev/                 # Dev environment patches
â”‚       â””â”€â”€ prod/                # Prod environment patches
â”œâ”€â”€ applications/                 # Managed by ArgoCD
â”‚   â””â”€â”€ arr-stack/
â”‚       â”œâ”€â”€ base/
â”‚       â”‚   â”œâ”€â”€ prowlarr/        # Indexer manager
â”‚       â”‚   â”œâ”€â”€ sonarr/          # TV automation
â”‚       â”‚   â”œâ”€â”€ radarr/          # Movie automation
â”‚       â”‚   â”œâ”€â”€ plex/            # Media server (primary)
â”‚       â”‚   â””â”€â”€ jellyfin/        # Media server (testing)
â”‚       â””â”€â”€ overlays/
â”‚           â”œâ”€â”€ dev/
â”‚           â””â”€â”€ prod/
â”œâ”€â”€ clusters/homelab-single/
â”œâ”€â”€ argocd-apps/
â””â”€â”€ docs/
```

---

## Phase 2: GitOps Foundation (Week 2)

### Goals

- Install FluxCD
- Install ArgoCD via Flux
- Deploy storage provisioners
- Migrate Traefik to Flux management

### Tasks

- [ ] Write `bootstrap-flux.sh` script
- [ ] Create Flux bootstrap manifests
- [ ] Install Flux to cluster
- [ ] Create GitRepository source
- [ ] Deploy NFS StorageClass
- [ ] Deploy local-path-provisioner
- [ ] Create ArgoCD Helm release (via Flux)
- [ ] Deploy ArgoCD
- [ ] Access ArgoCD UI
- [ ] Create root App-of-Apps

---

## Phase 3: Multi-Environment Setup (Week 3)

### Goals

- Create dev/prod namespaces
- Configure environment-specific routing
- Set up Kustomize overlays

### Tasks

- [ ] Create `media-dev` namespace with resource quotas
- [ ] Create `media-prod` namespace with resource quotas
- [ ] Configure Traefik for multi-env routing
- [ ] Create dev overlay (\*.dev.lab domains)
- [ ] Create prod overlay (\*.lab domains)
- [ ] Test routing isolation

---

## Phase 4: Storage Setup (Week 3)

### Synology NFS Configuration

```
/volume1/media/           # RWX - Shared media library
â”œâ”€â”€ tv/                   # TV shows
â”œâ”€â”€ movies/               # Movies
â””â”€â”€ music/                # Music

/volume1/downloads/       # RWX - Download client
â”œâ”€â”€ complete/             # Finished downloads
â””â”€â”€ incomplete/           # In-progress downloads
```

### Local Storage (SQLite - MUST be local, not NFS)

- Prowlarr config: 5Gi RWO
- Sonarr config: 10Gi RWO
- Radarr config: 10Gi RWO
- Plex metadata: 20Gi RWO
- Jellyfin config: 10Gi RWO

### Tasks

- [ ] Configure Synology NFS shares
- [ ] Create NFS StorageClass manifest
- [ ] Deploy local-path-provisioner
- [ ] Test NFS PVC provisioning
- [ ] Test local-path PVC provisioning
- [ ] Create PVC templates for all apps

---

## Phase 5: Monitoring Stack (Week 4)

### kube-Prometheus-stack Components

- Prometheus Operator
- Prometheus (metrics collection)
- Alertmanager (alert routing)
- Grafana (visualization)
- node-exporter (node metrics)
- kube-state-metrics (K8s metrics)

### Tasks

- [ ] Create kube-Prometheus-stack HelmRelease
- [ ] Configure Prometheus storage (20Gi PVC)
- [ ] Configure Grafana admin password
- [ ] Create IngressRoutes (Grafana.dev.lab, Prometheus.dev.lab)
- [ ] Import arr stack dashboards
- [ ] Create custom dashboards for Plex/Jellyfin comparison
- [ ] Configure ServiceMonitors for arr apps
- [ ] Test metrics collection

---

## Phase 6: Arr Stack + Media Servers (Week 4-5)

### Deployment Order

1. **Prowlarr** (indexer manager) - Deploy first
2. **Sonarr** (TV) - Connect to Prowlarr
3. **Radarr** (Movies) - Connect to Prowlarr
4. **Plex** (primary media server)
5. **Jellyfin** (comparison/testing)

### Media Server Comparison Goals

- Side-by-side performance testing
- UI/UX comparison
- Resource usage monitoring (Grafana dashboards)
- Transcoding performance
- Mobile app experience
- Choose primary server after testing

### IngressRoutes

**Dev Environment**:

- `prowlarr.dev.lab` â†’ Prowlarr
- `sonarr.dev.lab` â†’ Sonarr
- `radarr.dev.lab` â†’ Radarr
- `plex.dev.lab` â†’ Plex
- `jellyfin.dev.lab` â†’ Jellyfin

**Prod Environment**:

- `prowlarr.lab` â†’ Prowlarr
- `sonarr.lab` â†’ Sonarr
- `radarr.lab` â†’ Radarr
- `plex.lab` â†’ Plex
- `jellyfin.lab` â†’ Jellyfin

### Tasks

- [ ] Create Prowlarr manifests (deployment, service, PVC, ingressroute)
- [ ] Create Sonarr manifests
- [ ] Create Radarr manifests
- [ ] Create Plex manifests
- [ ] Create Jellyfin manifests
- [ ] Create dev/prod overlays
- [ ] Deploy to dev environment
- [ ] Configure Prowlarr indexers
- [ ] Connect Sonarr â†’ Prowlarr
- [ ] Connect Radarr â†’ Prowlarr
- [ ] Test TV show search/download
- [ ] Test movie search/download
- [ ] Verify media in both Plex and Jellyfin
- [ ] Compare Plex vs Jellyfin performance
- [ ] Deploy to prod environment

---

## Phase 7: Documentation & Finalization (Week 6)

### Documentation

- [ ] Architecture diagram
- [ ] Plex vs Jellyfin comparison report
- [ ] Deployment procedures
- [ ] Troubleshooting guide
- [ ] Backup/restore procedures

### Taskfile Commands

```bash
# GitOps
task bootstrap-flux
task bootstrap-argocd
task sync-flux
task sync-argocd

# Storage
task setup-storage
task test-storage

# Arr Stack
task deploy-arr-dev
task deploy-arr-prod

# Monitoring
task grafana-ui
task prometheus-ui

# Media Servers
task plex-ui
task jellyfin-ui
```

---

## Environment Configuration

### Dev Environment (`media-dev`)

- **Namespace**: `media-dev`
- **Domains**: `*.dev.lab`
- **Resources**: Lower limits for testing
- **Logging**: DEBUG level
- **Purpose**: Testing new configurations

### Prod Environment (`media-prod`)

- **Namespace**: `media-prod`
- **Domains**: `*.lab`
- **Resources**: Higher limits for performance
- **Logging**: INFO level
- **Purpose**: Stable media consumption

---

## Plex vs Jellyfin Comparison

### Will Track

- **Performance**: Response time, load time
- **Resource Usage**: CPU, memory (monitored in Grafana)
- **Transcoding**: Quality, speed, format support
- **Features**: Mobile apps, sharing, user management
- **UI/UX**: Ease of use, aesthetics
- **Stability**: Uptime, crashes

### Both Share Same

- Media library (Synology NFS `/volume1/media`)
- Same hardware resources
- Same network configuration

### Decision Point

After 2-4 weeks of testing, choose primary server:

- Keep both if needed
- Or standardize on one
- Track decision in this document

---

## Storage Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Synology NAS (NFS)                â”‚
â”‚  /volume1/media (RWX) - Shared by all      â”‚
â”‚  /volume1/downloads (RWX) - Shared by all  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ NFS Mount
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Kubernetes Cluster (Talos)          â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Apps with SQLite (Local Storage)   â”‚  â”‚
â”‚  â”‚  - Prowlarr config (5Gi RWO)        â”‚  â”‚
â”‚  â”‚  - Sonarr config (10Gi RWO)         â”‚  â”‚
â”‚  â”‚  - Radarr config (10Gi RWO)         â”‚  â”‚
â”‚  â”‚  - Plex metadata (20Gi RWO)         â”‚  â”‚
â”‚  â”‚  - Jellyfin config (10Gi RWO)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                             â”‚
â”‚  All apps mount NFS for media/downloads    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Testing Checklist

### Infrastructure

- [ ] Flux reconciles automatically
- [ ] ArgoCD syncs applications
- [ ] Traefik routes correctly to both envs
- [ ] NFS volumes mount successfully
- [ ] Local volumes provision correctly
- [ ] Prometheus collects metrics
- [ ] Grafana displays dashboards

### Arr Stack

- [ ] Prowlarr indexers working
- [ ] Sonarr finds TV shows
- [ ] Radarr finds movies
- [ ] Downloads complete successfully
- [ ] Media files organized correctly

### Media Servers

- [ ] Plex discovers media library
- [ ] Jellyfin discovers media library
- [ ] Both can stream without buffering
- [ ] Transcoding works (if needed)
- [ ] Mobile apps work (if testing)
- [ ] Remote access configured (optional)

---

## Next Actions

### This Week (Phase 1)

1. âœ… Create directory structure
2. Create namespace manifests
3. Create storage manifests
4. Create Flux bootstrap files
5. Create ArgoCD bootstrap files

### Next Week (Phase 2)

1. Install FluxCD
2. Deploy storage provisioners
3. Install ArgoCD
4. Test GitOps workflows

---

## Decision Log

**2025-11-09**: Added Both Plex and Jellyfin

- **Why**: User wants to test Jellyfin alongside Plex
- **Benefit**: Can compare performance and features side-by-side
- **Resource Impact**: ~2-4GB additional memory for second server
- **Monitoring**: Will track resource usage in Grafana to compare

**2025-11-09**: Dual GitOps (Flux + Argo)

- **Flux**: Infrastructure management (storage, traefik, monitoring)
- **ArgoCD**: Application management (arr stack, media servers)
- **Benefit**: Clean separation, better UI for apps

**2025-11-09**: Namespace-based Environments

- **Dev + Prod** in same cluster
- **Benefit**: Simpler for single-node, adequate isolation

---

## Issues & Blockers

### Current Blockers

None

### Known Risks

1. **SQLite on NFS**: Must use local storage for configs
2. **Single-Node**: No HA, need good backups
3. **Resource Usage**: Plex + Jellyfin + Monitoring may be heavy

---

**Last Updated**: 2025-11-09 16:05 PST
**Next Review**: Daily during Phase 1-2
