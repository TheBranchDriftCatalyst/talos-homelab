# Ollama LLM Inference - Kustomization
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources: []
  # TODO: Add ollama resources when ready
  # - deployment.yaml
  # - service.yaml
  # - ingressroute.yaml
  # - pvc-models.yaml
