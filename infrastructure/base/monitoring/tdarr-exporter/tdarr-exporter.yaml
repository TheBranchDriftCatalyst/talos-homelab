---
# Tdarr Prometheus Exporter
# Scrapes Tdarr API and exposes metrics for Grafana dashboards
# Deployed to monitoring namespace to avoid media quota limits
apiVersion: v1
kind: ConfigMap
metadata:
  name: tdarr-exporter-script
  namespace: monitoring
  labels:
    app: tdarr-exporter
data:
  exporter.py: |
    #!/usr/bin/env python3
    """Tdarr Prometheus Exporter - exposes transcoding metrics"""
    import json
    import time
    import urllib.request
    import http.server
    import os

    TDARR_URL = os.environ.get('TDARR_URL', 'http://tdarr.media.svc.cluster.local:8265')
    METRICS_PORT = int(os.environ.get('METRICS_PORT', '9092'))
    SCRAPE_INTERVAL = int(os.environ.get('SCRAPE_INTERVAL', '30'))

    def fetch_stats():
        """Fetch statistics from Tdarr API"""
        try:
            req = urllib.request.Request(
                f'{TDARR_URL}/api/v2/cruddb',
                data=json.dumps({"data": {"collection": "StatisticsJSONDB", "mode": "getAll"}}).encode(),
                headers={'Content-Type': 'application/json'},
                method='POST'
            )
            with urllib.request.urlopen(req, timeout=10) as resp:
                data = json.loads(resp.read().decode())
                return data[0] if data else {}
        except Exception as e:
            print(f"Error fetching stats: {e}")
            return {}

    def fetch_nodes():
        """Fetch node information from Tdarr API"""
        try:
            req = urllib.request.Request(
                f'{TDARR_URL}/api/v2/cruddb',
                data=json.dumps({"data": {"collection": "NodeJSONDB", "mode": "getAll"}}).encode(),
                headers={'Content-Type': 'application/json'},
                method='POST'
            )
            with urllib.request.urlopen(req, timeout=10) as resp:
                return json.loads(resp.read().decode())
        except Exception as e:
            print(f"Error fetching nodes: {e}")
            return []

    def generate_metrics():
        """Generate Prometheus metrics"""
        stats = fetch_stats()
        nodes = fetch_nodes()

        lines = []
        lines.append('# HELP tdarr_total_files Total number of files tracked by Tdarr')
        lines.append('# TYPE tdarr_total_files gauge')
        lines.append(f'tdarr_total_files {stats.get("totalFileCount", 0)}')

        lines.append('# HELP tdarr_transcode_count Total number of transcodes completed')
        lines.append('# TYPE tdarr_transcode_count counter')
        lines.append(f'tdarr_transcode_count {stats.get("totalTranscodeCount", 0)}')

        lines.append('# HELP tdarr_health_check_count Total number of health checks completed')
        lines.append('# TYPE tdarr_health_check_count counter')
        lines.append(f'tdarr_health_check_count {stats.get("totalHealthCheckCount", 0)}')

        lines.append('# HELP tdarr_size_diff_gb Space saved in GB from transcoding')
        lines.append('# TYPE tdarr_size_diff_gb gauge')
        lines.append(f'tdarr_size_diff_gb {stats.get("sizeDiff", 0)}')

        lines.append('# HELP tdarr_score Tdarr optimization score')
        lines.append('# TYPE tdarr_score gauge')
        score = stats.get("tdarrScore", "0")
        lines.append(f'tdarr_score {float(score) if score else 0}')

        lines.append('# HELP tdarr_health_check_score Health check score percentage')
        lines.append('# TYPE tdarr_health_check_score gauge')
        health_score = stats.get("healthCheckScore", "0")
        lines.append(f'tdarr_health_check_score {float(health_score) if health_score else 0}')

        lines.append('# HELP tdarr_db_queue Database queue size')
        lines.append('# TYPE tdarr_db_queue gauge')
        lines.append(f'tdarr_db_queue {stats.get("DBQueue", 0)}')

        # Queue tables (table0=transcoding, table1=transcode success, etc.)
        lines.append('# HELP tdarr_queue_transcode Files currently being transcoded')
        lines.append('# TYPE tdarr_queue_transcode gauge')
        lines.append(f'tdarr_queue_transcode {stats.get("table0Count", 0)}')

        lines.append('# HELP tdarr_queue_transcode_success Files successfully transcoded')
        lines.append('# TYPE tdarr_queue_transcode_success gauge')
        lines.append(f'tdarr_queue_transcode_success {stats.get("table1Count", 0)}')

        lines.append('# HELP tdarr_queue_transcode_error Files with transcode errors')
        lines.append('# TYPE tdarr_queue_transcode_error gauge')
        lines.append(f'tdarr_queue_transcode_error {stats.get("table2Count", 0)}')

        lines.append('# HELP tdarr_queue_health_check Files being health checked')
        lines.append('# TYPE tdarr_queue_health_check gauge')
        lines.append(f'tdarr_queue_health_check {stats.get("table3Count", 0)}')

        # Note: Tdarr table4 = HealthCheckError, table5 = HealthCheckSuccess
        lines.append('# HELP tdarr_queue_health_check_success Files passed health check')
        lines.append('# TYPE tdarr_queue_health_check_success gauge')
        lines.append(f'tdarr_queue_health_check_success {stats.get("table5Count", 0)}')

        lines.append('# HELP tdarr_queue_health_check_error Files failed health check')
        lines.append('# TYPE tdarr_queue_health_check_error gauge')
        lines.append(f'tdarr_queue_health_check_error {stats.get("table4Count", 0)}')

        lines.append('# HELP tdarr_queue_staged Files staged for processing')
        lines.append('# TYPE tdarr_queue_staged gauge')
        lines.append(f'tdarr_queue_staged {stats.get("table6Count", 0)}')

        # Node metrics
        lines.append('# HELP tdarr_nodes_total Total number of Tdarr worker nodes')
        lines.append('# TYPE tdarr_nodes_total gauge')
        lines.append(f'tdarr_nodes_total {len(nodes)}')

        active_nodes = sum(1 for n in nodes if not n.get('nodePaused', True))
        lines.append('# HELP tdarr_nodes_active Number of active (non-paused) nodes')
        lines.append('# TYPE tdarr_nodes_active gauge')
        lines.append(f'tdarr_nodes_active {active_nodes}')

        # Per-node GPU workers configured
        for node in nodes:
            node_id = node.get('_id', 'unknown').replace('-', '_').replace('.', '_')
            max_gpu = node.get('maxGpuWorkers', 0)
            paused = 1 if node.get('nodePaused', False) else 0
            lines.append(f'tdarr_node_gpu_workers{{node="{node.get("_id", "unknown")}"}} {max_gpu}')
            lines.append(f'tdarr_node_paused{{node="{node.get("_id", "unknown")}"}} {paused}')

        lines.append('# HELP tdarr_up Tdarr exporter is up')
        lines.append('# TYPE tdarr_up gauge')
        lines.append(f'tdarr_up 1')

        return '\n'.join(lines) + '\n'

    class MetricsHandler(http.server.BaseHTTPRequestHandler):
        def do_GET(self):
            if self.path == '/metrics':
                metrics = generate_metrics()
                self.send_response(200)
                self.send_header('Content-Type', 'text/plain')
                self.end_headers()
                self.wfile.write(metrics.encode())
            elif self.path == '/health':
                self.send_response(200)
                self.send_header('Content-Type', 'text/plain')
                self.end_headers()
                self.wfile.write(b'OK\n')
            else:
                self.send_response(404)
                self.end_headers()

        def log_message(self, format, *args):
            pass  # Suppress logging

    if __name__ == '__main__':
        print(f"Starting Tdarr exporter on port {METRICS_PORT}")
        print(f"Scraping Tdarr at: {TDARR_URL}")
        server = http.server.HTTPServer(('0.0.0.0', METRICS_PORT), MetricsHandler)
        server.serve_forever()
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tdarr-exporter
  namespace: monitoring
  labels:
    app: tdarr-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tdarr-exporter
  template:
    metadata:
      labels:
        app: tdarr-exporter
      # Note: Scraped via ServiceMonitor (not pod annotations) to avoid duplicates
    spec:
      containers:
        - name: exporter
          image: python:3.11-alpine
          command: ["python", "/scripts/exporter.py"]
          ports:
            - name: metrics
              containerPort: 9092
              protocol: TCP
          env:
            - name: TDARR_URL
              value: "http://tdarr-server.tdarr.svc.cluster.local:8265"
            - name: METRICS_PORT
              value: "9092"
          volumeMounts:
            - name: script
              mountPath: /scripts
          resources:
            requests:
              cpu: 5m
              memory: 64Mi
          livenessProbe:
            httpGet:
              path: /health
              port: 9092
            initialDelaySeconds: 10
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /health
              port: 9092
            initialDelaySeconds: 5
            periodSeconds: 10
      volumes:
        - name: script
          configMap:
            name: tdarr-exporter-script
            defaultMode: 0755
---
apiVersion: v1
kind: Service
metadata:
  name: tdarr-exporter
  namespace: monitoring
  labels:
    app: tdarr-exporter
spec:
  type: ClusterIP
  ports:
    - name: metrics
      port: 9092
      targetPort: 9092
      protocol: TCP
  selector:
    app: tdarr-exporter
---
# ServiceMonitor for Prometheus Operator
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: tdarr-exporter
  namespace: monitoring
  labels:
    app: tdarr-exporter
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: tdarr-exporter
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
